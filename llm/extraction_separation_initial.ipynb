{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65af8259-6da9-4c2e-9a73-44f4a83f634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessities\n",
    "from pathlib import Path\n",
    "import fitz\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566fcca0-0957-4edc-83f3-99ece145022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing psychpaper14.pdf\n",
      "Processing psychpaper15.pdf\n",
      "Processing psychpaper01.pdf\n",
      "Processing psychpaper17.pdf\n",
      "Processing psychpaper03.pdf\n",
      "Processing psychpaper02.pdf\n",
      "Processing psychpaper16.pdf\n",
      "Processing psychpaper12.pdf\n",
      "Processing psychpaper07.pdf\n",
      "Processing psychpaper13.pdf\n",
      "Processing psychpaper05.pdf\n",
      "Processing psychpaper11.pdf\n",
      "Processing psychpaper10.pdf\n",
      "Processing psychpaper04.pdf\n",
      "Processing psychpaper21.pdf\n",
      "Processing psychpaper09.pdf\n",
      "Processing psychpaper08.pdf\n",
      "Processing psychpaper20.pdf\n",
      "Processing psychpaper22.pdf\n",
      "Processing psychpaper23.pdf\n",
      "Processing psychpaper18.pdf\n",
      "Processing psychpaper24.pdf\n",
      "Processing psychpaper25.pdf\n",
      "Processing psychpaper19.pdf\n",
      "Extraction complete. Data saved to /Users/nataliepegues/data4380.np/llm_workspace/data/papers.json\n"
     ]
    }
   ],
   "source": [
    "# establishing path variables\n",
    "PDF_DIR = Path(\"/Users/nataliepegues/data4380.np/llm_workspace/data\")\n",
    "OUTPUT_JSON = Path(\"/Users/nataliepegues/data4380.np/llm_workspace/data/papers.json\")\n",
    "\n",
    "# function for pdf text extraction\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in doc:\n",
    "        full_text += page.get_text()\n",
    "    return full_text\n",
    "\n",
    "# function to split text between abstract and body, w/ accommodations for different formats / word choice\n",
    "def split_abstract_and_body(text):\n",
    "    text = text.lower()\n",
    "    abstract_start = text.find(\"abstract\")\n",
    "    if abstract_start == -1:\n",
    "        return \"\", text\n",
    "        \n",
    "    intro_start = text.find(\"introduction\", abstract_start)\n",
    "    if intro_start == -1:\n",
    "        intro_start = text.find(\"\\n1\", abstract_start)\n",
    "        \n",
    "    if intro_start == -1:\n",
    "        intro_start = abstract_start + 1000\n",
    "    abstract = text[abstract_start:intro_start].strip()\n",
    "    body = text[intro_start:].strip()\n",
    "    return abstract, body\n",
    "\n",
    "papers_data = []\n",
    "\n",
    "# looping over each file in the directory to separate and put text into pdf\n",
    "for pdf_file in PDF_DIR.glob(\"*.pdf\"):\n",
    "    print(f\"Processing {pdf_file.name}\")\n",
    "    full_text = extract_text_from_pdf(pdf_file)\n",
    "    abstract, body = split_abstract_and_body(full_text)\n",
    "    papers_data.append({\n",
    "        \"filename\": pdf_file.name,\n",
    "        \"abstract\": abstract,\n",
    "        \"body\": body\n",
    "    })\n",
    "\n",
    "with open(OUTPUT_JSON, \"w\") as f:\n",
    "    json.dump(papers_data, f, indent=2)\n",
    "\n",
    "print(f\"Extraction complete. Data saved to {OUTPUT_JSON}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm-venv)",
   "language": "python",
   "name": "llm-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
